{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b61574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukhmanpreetsingh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1119 - val_loss: 0.0498\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0460 - val_loss: 0.0376\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0364 - val_loss: 0.0314\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0307 - val_loss: 0.0272\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0271 - val_loss: 0.0249\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0251 - val_loss: 0.0232\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0233 - val_loss: 0.0218\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0221 - val_loss: 0.0208\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0211 - val_loss: 0.0200\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0202 - val_loss: 0.0193\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m Adam())\n\u001b[1;32m     22\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mfit(train_x, train_x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(val_x, val_x))\n\u001b[0;32m---> 24\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Model(autoencoder\u001b[38;5;241m.\u001b[39minput, autoencoder\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m     25\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpredict(train_x)  \u001b[38;5;66;03m# bottleneck representation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mpredict(train_x)        \u001b[38;5;66;03m# reconstruction\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/ops/operation.py:276\u001b[0m, in \u001b[0;36mOperation.input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/ops/operation.py:307\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "train_x = x_train.reshape(60000, 784) / 255\n",
    "val_x = x_test.reshape(10000, 784) / 255\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "\n",
    "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10, verbose=1, validation_data=(val_x, val_x))\n",
    "\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "encoding_dim = 10\n",
    "\n",
    "# return the decoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder = autoencoder.layers[-3](encoded_input)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15e2a6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (791625142.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    img = image.load_img(\"C:\\Users\\meenakshi.h\\Desktop\\Images\\fig12.png\", target_size=(28, 28), color_mode = \"grayscale\")\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "from keras.preprocessing import image\n",
    "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
    "img = image.load_img(\"C:\\Users\\meenakshi.h\\Desktop\\Images\\fig12.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
    "input_img = image.img_to_array(img)\n",
    "inputs = input_img.reshape(1,784)\n",
    "target_data = autoencoder.predict(inputs)\n",
    "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
    "print(dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
